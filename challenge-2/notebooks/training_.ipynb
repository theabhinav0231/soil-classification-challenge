{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":102966,"databundleVersionId":12412856,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix, roc_auc_score\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.covariance import EllipticEnvelope\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:44:05.218373Z","iopub.execute_input":"2025-05-25T10:44:05.218719Z","iopub.status.idle":"2025-05-25T10:44:05.225874Z","shell.execute_reply.started":"2025-05-25T10:44:05.218688Z","shell.execute_reply":"2025-05-25T10:44:05.225035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# device agnostic code\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:27:05.242183Z","iopub.execute_input":"2025-05-25T10:27:05.242522Z","iopub.status.idle":"2025-05-25T10:27:05.299004Z","shell.execute_reply.started":"2025-05-25T10:27:05.242503Z","shell.execute_reply":"2025-05-25T10:27:05.298269Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hyperparameters and file path configuration\nCONFIG = {\n    'img_size': 224,\n    'batch_size': 32,\n    'epochs': 15,\n    'learning_rate': 2e-4,\n    'weight_decay': 1e-4,\n    'n_folds': 3,\n    'seed': 42,\n    'model_name': 'efficientnet_b0',\n    'early_stopping_patience': 5,\n    'contamination': 0.15,\n    'reconstruction_weight': 1.0,\n    'feature_weight': 0.5,\n    'train_images_dir' : \"/kaggle/input/soil-classification-part-2/soil_competition-2025/train\",\n    'test_images_dir' : \"/kaggle/input/soil-classification-part-2/soil_competition-2025/test\",\n    'train_csv_path' : \"/kaggle/input/soil-classification-part-2/soil_competition-2025/train_labels.csv\",\n    'test_csv_path' : \"/kaggle/input/soil-classification-part-2/soil_competition-2025/test_ids.csv\",\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:27:05.299878Z","iopub.execute_input":"2025-05-25T10:27:05.300159Z","iopub.status.idle":"2025-05-25T10:27:05.318346Z","shell.execute_reply.started":"2025-05-25T10:27:05.300136Z","shell.execute_reply":"2025-05-25T10:27:05.317687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# seed for reproducibility\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(CONFIG['seed'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:27:05.319690Z","iopub.execute_input":"2025-05-25T10:27:05.319906Z","iopub.status.idle":"2025-05-25T10:27:05.335902Z","shell.execute_reply.started":"2025-05-25T10:27:05.319881Z","shell.execute_reply":"2025-05-25T10:27:05.335164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# input data structure\nclass SoilDataset(Dataset):\n    def __init__(self, image_paths, transforms=None, is_test=False):\n        self.image_paths = image_paths\n        self.transforms = transforms\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n\n        # Load image\n        image = cv2.imread(img_path)\n        if image is None:\n            image = np.zeros((224, 224, 3), dtype=np.uint8)\n        else:\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        # Keep original for reconstruction loss\n        original_image = image.copy()\n\n        # Apply transforms\n        if self.transforms:\n            transformed = self.transforms(image=image)\n            image = transformed['image']\n        else:\n            # Ensure consistent tensor creation\n            image = image.astype(np.float32) / 255.0\n            image = torch.from_numpy(image.transpose(2, 0, 1)).contiguous()\n\n        if self.is_test:\n            return image\n        else:\n            # Apply same base transforms to original for consistent dimensions\n            if self.transforms:\n                # Create a simple transform for original\n                original_transform = A.Compose([\n                    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                    ToTensorV2()\n                ])\n                original_transformed = original_transform(image=original_image)\n                original_tensor = original_transformed['image']\n            else:\n                original_image = original_image.astype(np.float32) / 255.0\n                original_tensor = torch.from_numpy(original_image.transpose(2, 0, 1)).contiguous()\n            \n            return image, original_tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:44:32.904110Z","iopub.execute_input":"2025-05-25T10:44:32.904405Z","iopub.status.idle":"2025-05-25T10:44:32.912294Z","shell.execute_reply.started":"2025-05-25T10:44:32.904383Z","shell.execute_reply":"2025-05-25T10:44:32.911641Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data augmentation\ndef get_transforms(phase):\n    if phase == 'train':\n        return A.Compose([\n            A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.3),\n            A.Rotate(limit=30, p=0.5),\n            A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n            A.HueSaturationValue(hue_shift_limit=8, sat_shift_limit=15, val_shift_limit=8, p=0.4),\n            A.GaussNoise(var_limit=(5.0, 25.0), p=0.3),\n            A.GaussianBlur(blur_limit=3, p=0.2),\n            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.3),\n            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.4),\n            A.CoarseDropout(max_holes=4, max_height=16, max_width=16, p=0.2),\n            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            ToTensorV2()\n        ])\n    else:\n        return A.Compose([\n            A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            ToTensorV2()\n        ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:44:49.434842Z","iopub.execute_input":"2025-05-25T10:44:49.435511Z","iopub.status.idle":"2025-05-25T10:44:49.441657Z","shell.execute_reply.started":"2025-05-25T10:44:49.435487Z","shell.execute_reply":"2025-05-25T10:44:49.440950Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model initialization\nclass SoilAutoencoder(nn.Module):\n    def __init__(self, model_name='efficientnet_b0', pretrained=True):\n        super(SoilAutoencoder, self).__init__()\n        \n        # Encoder\n        if model_name == 'efficientnet_b0':\n            self.encoder_backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1 if pretrained else None)\n            in_features = self.encoder_backbone.classifier[1].in_features\n            self.encoder_backbone.classifier = nn.Identity()\n        \n        # Feature compression layers\n        self.encoder = nn.Sequential(\n            nn.Linear(in_features, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, 256),  # Bottleneck layer\n        )\n        \n        # Decoder layers\n        self.decoder = nn.Sequential(\n            nn.Linear(256, 512),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(1024, 2048),\n            nn.ReLU(),\n            nn.Linear(2048, 3 * CONFIG['img_size'] * CONFIG['img_size']),\n            nn.Sigmoid()\n        )\n        \n        #  layers for feature-based anomaly detection\n        self.feature_classifier = nn.Sequential(\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1),  # Anomaly score\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x):\n        batch_size = x.size(0)\n        \n        # Encode\n        backbone_features = self.encoder_backbone(x)\n        encoded = self.encoder(backbone_features)\n        \n        # Decode\n        decoded = self.decoder(encoded)\n        decoded = decoded.view(batch_size, 3, CONFIG['img_size'], CONFIG['img_size'])\n        \n        # Anomaly score\n        anomaly_score = self.feature_classifier(encoded)\n        \n        return decoded, encoded, anomaly_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:45:06.340871Z","iopub.execute_input":"2025-05-25T10:45:06.341367Z","iopub.status.idle":"2025-05-25T10:45:06.349610Z","shell.execute_reply.started":"2025-05-25T10:45:06.341344Z","shell.execute_reply":"2025-05-25T10:45:06.348791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class OneClassLoss(nn.Module):\n    def __init__(self, reconstruction_weight=1.0, feature_weight=0.5, center_weight=0.3):\n        super(OneClassLoss, self).__init__()\n        self.reconstruction_weight = reconstruction_weight\n        self.feature_weight = feature_weight\n        self.center_weight = center_weight\n        self.mse_loss = nn.MSELoss()\n        self.center = None\n        \n    def update_center(self, features):\n        \"\"\"Update the center of normal features\"\"\"\n        if self.center is None:\n            self.center = torch.mean(features, dim=0)\n        else:\n            # Moving average\n            self.center = 0.9 * self.center + 0.1 * torch.mean(features, dim=0)\n    \n    def forward(self, reconstructed, original, features, anomaly_scores):\n        # Reconstruction loss\n        recon_loss = self.mse_loss(reconstructed, original)\n        \n        # Feature-based loss, encourage normal samples to have low anomaly scores\n        feature_loss = torch.mean(anomaly_scores)\n        \n        # Center loss, encourage features to be close to center\n        if self.center is not None:\n            center_loss = torch.mean(torch.sum((features - self.center.detach()) ** 2, dim=1))\n        else:\n            center_loss = torch.tensor(0.0, device=features.device)\n        \n        total_loss = (self.reconstruction_weight * recon_loss + \n                     self.feature_weight * feature_loss +\n                     self.center_weight * center_loss)\n        \n        return total_loss, recon_loss, feature_loss, center_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:45:34.225811Z","iopub.execute_input":"2025-05-25T10:45:34.226089Z","iopub.status.idle":"2025-05-25T10:45:34.232456Z","shell.execute_reply.started":"2025-05-25T10:45:34.226068Z","shell.execute_reply":"2025-05-25T10:45:34.231864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# training loop\ndef train_epoch(model, dataloader, criterion, optimizer, device, epoch):\n    model.train()\n    running_loss = 0.0\n    running_recon_loss = 0.0\n    running_feature_loss = 0.0\n    running_center_loss = 0.0\n\n    for batch_idx, (images, originals) in enumerate(dataloader):\n        images, originals = images.to(device, non_blocking=True), originals.to(device, non_blocking=True)\n\n        optimizer.zero_grad()\n\n        # Forward pass\n        reconstructed, features, anomaly_scores = model(images)\n\n        # Update center\n        criterion.update_center(features)\n\n        # Calculate loss\n        total_loss, recon_loss, feature_loss, center_loss = criterion(\n            reconstructed, originals, features, anomaly_scores)\n\n        # Backward pass\n        total_loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n\n        # Statistics\n        running_loss += total_loss.item()\n        running_recon_loss += recon_loss.item()\n        running_feature_loss += feature_loss.item()\n        running_center_loss += center_loss.item()\n\n        # Clear cache periodically\n        if batch_idx % 50 == 0:\n            torch.cuda.empty_cache()\n\n    epoch_loss = running_loss / len(dataloader)\n    epoch_recon_loss = running_recon_loss / len(dataloader)\n    epoch_feature_loss = running_feature_loss / len(dataloader)\n    epoch_center_loss = running_center_loss / len(dataloader)\n\n    return epoch_loss, epoch_recon_loss, epoch_feature_loss, epoch_center_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:46:19.909884Z","iopub.execute_input":"2025-05-25T10:46:19.910122Z","iopub.status.idle":"2025-05-25T10:46:19.916627Z","shell.execute_reply.started":"2025-05-25T10:46:19.910106Z","shell.execute_reply":"2025-05-25T10:46:19.915603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# validation loop\ndef validate_epoch(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    running_recon_loss = 0.0\n    running_feature_loss = 0.0\n    running_center_loss = 0.0\n\n    with torch.no_grad():\n        for images, originals in dataloader:\n            images, originals = images.to(device), originals.to(device)\n\n            reconstructed, features, anomaly_scores = model(images)\n            total_loss, recon_loss, feature_loss, center_loss = criterion(\n                reconstructed, originals, features, anomaly_scores)\n\n            running_loss += total_loss.item()\n            running_recon_loss += recon_loss.item()\n            running_feature_loss += feature_loss.item()\n            running_center_loss += center_loss.item()\n\n    epoch_loss = running_loss / len(dataloader)\n    epoch_recon_loss = running_recon_loss / len(dataloader)\n    epoch_feature_loss = running_feature_loss / len(dataloader)\n    epoch_center_loss = running_center_loss / len(dataloader)\n\n    return epoch_loss, epoch_recon_loss, epoch_feature_loss, epoch_center_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:46:38.667005Z","iopub.execute_input":"2025-05-25T10:46:38.667716Z","iopub.status.idle":"2025-05-25T10:46:38.672862Z","shell.execute_reply.started":"2025-05-25T10:46:38.667692Z","shell.execute_reply":"2025-05-25T10:46:38.672127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_data():\n    # Load training data\n    train_df = pd.read_csv(CONFIG['train_csv_path'])\n    print(f\"Loaded train.csv with {len(train_df)} rows\")\n\n    train_images = []\n\n    image_col = 'image_id'\n    if image_col not in train_df.columns:\n        image_col = train_df.columns[0]\n\n    for idx, row in train_df.iterrows():\n        image_name = str(row[image_col])\n\n        for ext in ['', '.jpg', '.jpeg', '.png', '.bmp']:\n            img_path = os.path.join(CONFIG['train_images_dir'], image_name + ext)\n            if os.path.exists(img_path):\n                train_images.append(img_path)\n                break\n        else:\n            img_path = os.path.join(CONFIG['train_images_dir'], image_name)\n            if os.path.exists(img_path):\n                train_images.append(img_path)\n\n    print(f\"Found {len(train_images)} valid training images\")\n    return train_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:46:54.931126Z","iopub.execute_input":"2025-05-25T10:46:54.931830Z","iopub.status.idle":"2025-05-25T10:46:54.937360Z","shell.execute_reply.started":"2025-05-25T10:46:54.931804Z","shell.execute_reply":"2025-05-25T10:46:54.936649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_features(model, dataloader, device):\n    model.eval()\n    features_list = []\n    anomaly_scores_list = []\n    recon_errors_list = []\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            if isinstance(batch, tuple):\n                images, originals = batch\n                originals = originals.to(device)\n            else:\n                images = batch\n                originals = None\n            \n            images = images.to(device)\n            reconstructed, features, anomaly_scores = model(images)\n            \n            features_list.append(features.cpu().numpy())\n            anomaly_scores_list.append(anomaly_scores.cpu().numpy())\n            \n            if originals is not None:\n                recon_error = torch.mean((reconstructed - originals) ** 2, dim=[1, 2, 3])\n                recon_errors_list.append(recon_error.cpu().numpy())\n    \n    features = np.vstack(features_list)\n    anomaly_scores = np.vstack(anomaly_scores_list).flatten()\n    recon_errors = np.concatenate(recon_errors_list) if recon_errors_list else None\n    \n    return features, anomaly_scores, recon_errors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:47:28.379493Z","iopub.execute_input":"2025-05-25T10:47:28.380326Z","iopub.status.idle":"2025-05-25T10:47:28.386098Z","shell.execute_reply.started":"2025-05-25T10:47:28.380295Z","shell.execute_reply":"2025-05-25T10:47:28.385466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_class_model():\n    # Prepare data\n    train_images = prepare_data()\n\n    if len(train_images) == 0:\n        print(\"No training images found!\")\n        return None, []\n\n    # K-Fold Cross Validation\n    kf = KFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['seed'])\n    fold_models = []\n    fold_losses = []\n\n    for fold, (train_idx, val_idx) in enumerate(kf.split(train_images)):\n        print(f\"\\n{'='*50}\")\n        print(f\"FOLD {fold + 1}/{CONFIG['n_folds']}\")\n        print(f\"{'='*50}\")\n\n        # Split data\n        train_imgs = [train_images[i] for i in train_idx]\n        val_imgs = [train_images[i] for i in val_idx]\n\n        # Create datasets\n        train_dataset = SoilDataset(train_imgs, get_transforms('train'))\n        val_dataset = SoilDataset(val_imgs, get_transforms('val'))\n\n        # Create data loaders\n        train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'],\n                                shuffle=True, num_workers=2, pin_memory=True, \n                                persistent_workers=True, drop_last=True)\n        val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'],\n                              shuffle=False, num_workers=2, pin_memory=True,\n                              persistent_workers=True)\n\n        # Initialize model\n        model = SoilAutoencoder(CONFIG['model_name'], pretrained=True)\n        model.to(device)\n\n        # Initialize optimizer\n        optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'],\n                               weight_decay=CONFIG['weight_decay'])\n        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'])\n\n        # Initialize loss function\n        criterion = OneClassLoss(\n            reconstruction_weight=CONFIG['reconstruction_weight'],\n            feature_weight=CONFIG['feature_weight']\n        )\n\n        # Training loop\n        best_loss = float('inf')\n        patience_counter = 0\n\n        train_losses = []\n        val_losses = []\n\n        for epoch in range(CONFIG['epochs']):\n            # Train\n            train_loss, train_recon, train_feature, train_center = train_epoch(\n                model, train_loader, criterion, optimizer, device, epoch)\n\n            # Validate\n            val_loss, val_recon, val_feature, val_center = validate_epoch(\n                model, val_loader, criterion, device)\n\n            scheduler.step()\n\n            train_losses.append(train_loss)\n            val_losses.append(val_loss)\n\n            print(f'Epoch {epoch+1:02d}/{CONFIG[\"epochs\"]:02d} | '\n                  f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | '\n                  f'Recon: {val_recon:.4f} | Feature: {val_feature:.4f}')\n\n            # Save best model\n            if val_loss < best_loss:\n                best_loss = val_loss\n                torch.save(model.state_dict(), f'best_autoencoder_fold_{fold+1}.pth')\n                patience_counter = 0\n            else:\n                patience_counter += 1\n\n            # Early stopping\n            if patience_counter >= CONFIG['early_stopping_patience']:\n                print(f'Early stopping at epoch {epoch+1}')\n                break\n\n        # Load best model\n        model.load_state_dict(torch.load(f'best_autoencoder_fold_{fold+1}.pth'))\n        fold_models.append(model)\n        fold_losses.append(best_loss)\n\n        print(f'Fold {fold+1} Best Loss: {best_loss:.4f}')\n\n        # Plot training curves\n        plt.figure(figsize=(10, 4))\n        plt.subplot(1, 2, 1)\n        plt.plot(train_losses, label='Train Loss')\n        plt.plot(val_losses, label='Val Loss')\n        plt.title(f'Fold {fold+1} - Training Curves')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n\n        # Clear memory\n        del train_loader, val_loader\n        torch.cuda.empty_cache()\n\n    print(f\"\\nCross-validation completed!\")\n    print(f\"Fold losses: {fold_losses}\")\n    print(f\"Mean loss: {np.mean(fold_losses):.4f} ± {np.std(fold_losses):.4f}\")\n\n    return fold_models, fold_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:47:48.090766Z","iopub.execute_input":"2025-05-25T10:47:48.091032Z","iopub.status.idle":"2025-05-25T10:47:48.102954Z","shell.execute_reply.started":"2025-05-25T10:47:48.091012Z","shell.execute_reply":"2025-05-25T10:47:48.102264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict anomalies using ensemble of methods\ndef predict_anomalies(models, test_loader, train_loader, device):\n    # 1. Extract features from all models\n    all_test_features = []\n    all_test_anomaly_scores = []\n    all_test_recon_errors = []\n\n    for model in models:\n        test_features, test_anomaly_scores, test_recon_errors = extract_features(\n            model, test_loader, device)\n        all_test_features.append(test_features)\n        all_test_anomaly_scores.append(test_anomaly_scores)\n        if test_recon_errors is not None:\n            all_test_recon_errors.append(test_recon_errors)\n\n    # Average across models\n    avg_test_features = np.mean(all_test_features, axis=0)\n    avg_test_anomaly_scores = np.mean(all_test_anomaly_scores, axis=0)\n    avg_test_recon_errors = np.mean(all_test_recon_errors, axis=0) if all_test_recon_errors else None\n\n    # 2. Get training features for comparison\n    train_features_list = []\n    for model in models:\n        train_features, _, _ = extract_features(model, train_loader, device)\n        train_features_list.append(train_features)\n\n    avg_train_features = np.mean(train_features_list, axis=0)\n\n    # 3. Classical anomaly detection methods\n    predictions = {}\n\n    # One-Class SVM\n    scaler = StandardScaler()\n    train_features_scaled = scaler.fit_transform(avg_train_features)\n    test_features_scaled = scaler.transform(avg_test_features)\n\n    oc_svm = OneClassSVM(kernel='rbf', gamma='scale', nu=CONFIG['contamination'])\n    oc_svm.fit(train_features_scaled)\n    svm_pred = oc_svm.predict(test_features_scaled)\n    predictions['svm'] = np.where(svm_pred == 1, 1, 0)\n\n    # Isolation Forest\n    iso_forest = IsolationForest(contamination=CONFIG['contamination'], random_state=CONFIG['seed'])\n    iso_forest.fit(avg_train_features)\n    iso_pred = iso_forest.predict(avg_test_features)\n    predictions['isolation'] = np.where(iso_pred == 1, 1, 0)\n\n    # Elliptic Envelope\n    elliptic = EllipticEnvelope(contamination=CONFIG['contamination'], random_state=CONFIG['seed'])\n    elliptic.fit(train_features_scaled)\n    elliptic_pred = elliptic.predict(test_features_scaled)\n    predictions['elliptic'] = np.where(elliptic_pred == 1, 1, 0)\n\n    # Anomaly score threshold\n    anomaly_threshold = np.percentile(avg_test_anomaly_scores, (1 - CONFIG['contamination']) * 100)\n    predictions['anomaly_score'] = np.where(avg_test_anomaly_scores <= anomaly_threshold, 1, 0)\n\n    # Reconstruction error threshold\n    if avg_test_recon_errors is not None:\n        recon_threshold = np.percentile(avg_test_recon_errors, (1 - CONFIG['contamination']) * 100)\n        predictions['reconstruction'] = np.where(avg_test_recon_errors <= recon_threshold, 1, 0)\n\n    # Ensemble prediction (majority voting)\n    all_preds = np.array(list(predictions.values()))\n    ensemble_pred = np.where(np.mean(all_preds, axis=0) >= 0.5, 1, 0)\n\n    return ensemble_pred, predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:48:02.803211Z","iopub.execute_input":"2025-05-25T10:48:02.803767Z","iopub.status.idle":"2025-05-25T10:48:02.812467Z","shell.execute_reply.started":"2025-05-25T10:48:02.803746Z","shell.execute_reply":"2025-05-25T10:48:02.811884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_test_set(models):\n    # Load test data\n    test_df = pd.read_csv(CONFIG['test_csv_path'])\n    print(f\"Loaded test.csv with {len(test_df)} rows\")\n\n    test_images = []\n    image_col = 'image_id'\n    if image_col not in test_df.columns:\n        image_col = test_df.columns[0]\n\n    for idx, row in test_df.iterrows():\n        image_name = str(row[image_col])\n        for ext in ['', '.jpg', '.jpeg', '.png', '.bmp']:\n            img_path = os.path.join(CONFIG['test_images_dir'], image_name + ext)\n            if os.path.exists(img_path):\n                test_images.append(img_path)\n                break\n        else:\n            img_path = os.path.join(CONFIG['test_images_dir'], image_name)\n            if os.path.exists(img_path):\n                test_images.append(img_path)\n\n    print(f\"Found {len(test_images)} test images\")\n    train_images = prepare_data()\n    train_dataset = SoilDataset(train_images, get_transforms('val'))\n    test_dataset = SoilDataset(test_images, get_transforms('val'), is_test=True)\n\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'],\n                            shuffle=False, num_workers=2, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'],\n                           shuffle=False, num_workers=2, pin_memory=True)\n\n    # Make predictions\n    ensemble_pred, individual_preds = predict_anomalies(models, test_loader, train_loader, device)\n\n    # Show prediction breakdown\n    print(\"\\nPrediction Results:\")\n    for method, preds in individual_preds.items():\n        soil_count = np.sum(preds)\n        print(f\"{method:15}: Soil={soil_count:4d} ({soil_count/len(preds)*100:.1f}%), \"\n              f\"Non-soil={len(preds)-soil_count:4d} ({(len(preds)-soil_count)/len(preds)*100:.1f}%)\")\n\n    soil_count = np.sum(ensemble_pred)\n    print(f\"{'Ensemble':15}: Soil={soil_count:4d} ({soil_count/len(ensemble_pred)*100:.1f}%), \"\n          f\"Non-soil={len(ensemble_pred)-soil_count:4d} ({(len(ensemble_pred)-soil_count)/len(ensemble_pred)*100:.1f}%)\")\n\n    # Create submission\n    submission_df = pd.DataFrame({\n        'image_id': test_df[image_col],\n        'label': ensemble_pred\n    })\n\n    submission_df.to_csv('submission.csv', index=False)\n    print(\"\\nSubmission file created: submission.csv\")\n\n    return submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:48:17.874792Z","iopub.execute_input":"2025-05-25T10:48:17.875061Z","iopub.status.idle":"2025-05-25T10:48:17.884091Z","shell.execute_reply.started":"2025-05-25T10:48:17.875042Z","shell.execute_reply":"2025-05-25T10:48:17.883256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    models, fold_losses = train_one_class_model()\n\n    if models:\n        # Make predictions\n        submission_df = predict_test_set(models)\n\n        # Save best model\n        best_model_idx = np.argmin(fold_losses)\n        best_model = models[best_model_idx]\n\n        torch.save({\n            'model_state_dict': best_model.state_dict(),\n            'config': CONFIG,\n            'fold_losses': fold_losses,\n            'best_fold': best_model_idx + 1,\n        }, 'best_one_class_model.pth')\n\n        # Print completion statements\n        print(f\"\\nTraining completed!\")\n        print(f\"Best model from fold {best_model_idx + 1} saved as 'best_one_class_model.pth'\")\n        print(f\"Fold losses: {fold_losses}\")\n        print(f\"Mean loss: {np.mean(fold_losses):.4f} ± {np.std(fold_losses):.4f}\")\n    else:\n        print(\"Training failed - no models created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:48:27.588409Z","iopub.execute_input":"2025-05-25T10:48:27.588989Z","iopub.status.idle":"2025-05-25T10:56:37.320296Z","shell.execute_reply.started":"2025-05-25T10:48:27.588964Z","shell.execute_reply":"2025-05-25T10:56:37.319231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}