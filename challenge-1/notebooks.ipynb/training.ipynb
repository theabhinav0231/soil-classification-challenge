{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 102672,
          "databundleVersionId": 12375409,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "soil_classification",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "import gc\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "import timm\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# For data augmentation\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:26:35.700638Z",
          "iopub.execute_input": "2025-05-21T03:26:35.700935Z",
          "iopub.status.idle": "2025-05-21T03:26:49.985606Z",
          "shell.execute_reply.started": "2025-05-21T03:26:35.700912Z",
          "shell.execute_reply": "2025-05-21T03:26:49.984643Z"
        },
        "id": "vP-Hl63la-Vh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# replication seed\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:26:49.98701Z",
          "iopub.execute_input": "2025-05-21T03:26:49.987617Z",
          "iopub.status.idle": "2025-05-21T03:26:49.999593Z",
          "shell.execute_reply.started": "2025-05-21T03:26:49.987587Z",
          "shell.execute_reply": "2025-05-21T03:26:49.998795Z"
        },
        "id": "huc4g5-Ba-Vi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#device agnostic code\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:26:50.000736Z",
          "iopub.execute_input": "2025-05-21T03:26:50.001025Z",
          "iopub.status.idle": "2025-05-21T03:26:50.097792Z",
          "shell.execute_reply.started": "2025-05-21T03:26:50.001001Z",
          "shell.execute_reply": "2025-05-21T03:26:50.096624Z"
        },
        "id": "5wpViL63a-Vj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset file paths\n",
        "TRAIN_DIR = '/kaggle/input/soil-classification/soil_classification-2025/train'\n",
        "TEST_DIR = '/kaggle/input/soil-classification/soil_classification-2025/test'\n",
        "TRAIN_CSV = '/kaggle/input/soil-classification/soil_classification-2025/train_labels.csv'\n",
        "TEST_CSV = '/kaggle/input/soil-classification/soil_classification-2025/test_ids.csv'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:26:50.099479Z",
          "iopub.execute_input": "2025-05-21T03:26:50.099757Z",
          "iopub.status.idle": "2025-05-21T03:26:50.116355Z",
          "shell.execute_reply.started": "2025-05-21T03:26:50.099738Z",
          "shell.execute_reply": "2025-05-21T03:26:50.115359Z"
        },
        "id": "FoRB14GTa-Vj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset exploration\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "test_df = pd.read_csv(TEST_CSV)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:26:50.117292Z",
          "iopub.execute_input": "2025-05-21T03:26:50.11762Z",
          "iopub.status.idle": "2025-05-21T03:26:50.151347Z",
          "shell.execute_reply.started": "2025-05-21T03:26:50.117593Z",
          "shell.execute_reply": "2025-05-21T03:26:50.150579Z"
        },
        "id": "Nc9L5vLva-Vk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data shape:\", train_df.shape)\n",
        "print(\"\\nSample of training data:\")\n",
        "print(train_df.head())\n",
        "\n",
        "# Check class distribution\n",
        "print(\"\\nClass distribution in training data:\")\n",
        "class_dist = train_df['soil_type'].value_counts()\n",
        "print(class_dist)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:26:50.152221Z",
          "iopub.execute_input": "2025-05-21T03:26:50.152524Z",
          "iopub.status.idle": "2025-05-21T03:26:50.172957Z",
          "shell.execute_reply.started": "2025-05-21T03:26:50.152496Z",
          "shell.execute_reply": "2025-05-21T03:26:50.172099Z"
        },
        "id": "QlM4nxu3a-Vl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing\n",
        "soil_types = {\n",
        "    'Alluvial soil': 0,\n",
        "    'Black Soil': 1,\n",
        "    'Clay soil': 2,\n",
        "    'Red soil': 3\n",
        "}\n",
        "train_df['label'] = train_df['soil_type'].map(soil_types)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:26:50.17401Z",
          "iopub.execute_input": "2025-05-21T03:26:50.174316Z",
          "iopub.status.idle": "2025-05-21T03:26:50.186185Z",
          "shell.execute_reply.started": "2025-05-21T03:26:50.17429Z",
          "shell.execute_reply": "2025-05-21T03:26:50.185295Z"
        },
        "id": "1flx26CLa-Vm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def check_image_sizes(df, img_dir):\n",
        "    sizes = []\n",
        "    sample_size = min(100, len(df))\n",
        "    for i in range(sample_size):\n",
        "        img_path = os.path.join(img_dir, df.iloc[i]['image_id'])\n",
        "        img = Image.open(img_path)\n",
        "        sizes.append(img.size)\n",
        "\n",
        "    sizes_df = pd.DataFrame(sizes, columns=['width', 'height'])\n",
        "    print(\"Image size statistics:\")\n",
        "    print(sizes_df.describe())\n",
        "    return sizes_df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:26:55.025943Z",
          "iopub.execute_input": "2025-05-21T03:26:55.026657Z",
          "iopub.status.idle": "2025-05-21T03:26:55.03178Z",
          "shell.execute_reply.started": "2025-05-21T03:26:55.026632Z",
          "shell.execute_reply": "2025-05-21T03:26:55.030894Z"
        },
        "id": "-QwiBHrra-Vm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# data augmentation to ensure a diverse input data\n",
        "def get_train_transforms(img_size=384):\n",
        "    return A.Compose([\n",
        "        A.Resize(img_size, img_size),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Rotate(limit=30, p=0.7),\n",
        "        A.RandomBrightnessContrast(p=0.7),\n",
        "        A.HueSaturationValue(p=0.5),\n",
        "        A.OneOf([\n",
        "            A.GaussNoise(),\n",
        "            A.GaussianBlur(),\n",
        "            A.MotionBlur(),\n",
        "        ], p=0.3),\n",
        "        A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.5),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:43:38.203363Z",
          "iopub.execute_input": "2025-05-21T03:43:38.203998Z",
          "iopub.status.idle": "2025-05-21T03:43:38.209169Z",
          "shell.execute_reply.started": "2025-05-21T03:43:38.203972Z",
          "shell.execute_reply": "2025-05-21T03:43:38.208376Z"
        },
        "id": "vpnhC5iAa-Vn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# applying data augmentation to validation data\n",
        "def get_valid_transforms(img_size=384):\n",
        "    return A.Compose([\n",
        "        A.Resize(img_size, img_size),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:43:38.481996Z",
          "iopub.execute_input": "2025-05-21T03:43:38.482546Z",
          "iopub.status.idle": "2025-05-21T03:43:38.486733Z",
          "shell.execute_reply.started": "2025-05-21T03:43:38.48252Z",
          "shell.execute_reply": "2025-05-21T03:43:38.485883Z"
        },
        "id": "sWQecjr9a-Vo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up input data structure\n",
        "class SoilDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None, test=False):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.test = test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.df.iloc[idx]['image_id'])\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=img)\n",
        "            img = augmented['image']\n",
        "\n",
        "        if not self.test:\n",
        "            label = self.df.iloc[idx]['label']\n",
        "            return img, label\n",
        "        else:\n",
        "            return img"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:43:38.753372Z",
          "iopub.execute_input": "2025-05-21T03:43:38.753926Z",
          "iopub.status.idle": "2025-05-21T03:43:38.759773Z",
          "shell.execute_reply.started": "2025-05-21T03:43:38.753902Z",
          "shell.execute_reply": "2025-05-21T03:43:38.759013Z"
        },
        "id": "ZJ3VBywha-Vo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the model\n",
        "class SoilClassifier(nn.Module):\n",
        "    def __init__(self, model_name='efficientnet_b3', pretrained=True, num_classes=4):\n",
        "        super(SoilClassifier, self).__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
        "\n",
        "        # Get the number of features in the last layer\n",
        "        if 'efficientnet' in model_name:\n",
        "            n_features = self.model.classifier.in_features\n",
        "            self.model.classifier = nn.Identity()\n",
        "        else:  # For other models like ResNet\n",
        "            n_features = self.model.fc.in_features\n",
        "            self.model.fc = nn.Identity()\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(n_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.model(x)\n",
        "        features = self.dropout(features)\n",
        "        return self.classifier(features)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:43:38.977121Z",
          "iopub.execute_input": "2025-05-21T03:43:38.977612Z",
          "iopub.status.idle": "2025-05-21T03:43:38.98364Z",
          "shell.execute_reply.started": "2025-05-21T03:43:38.977588Z",
          "shell.execute_reply": "2025-05-21T03:43:38.982942Z"
        },
        "id": "bV_q_wiKa-Vo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# traning loop\n",
        "def train_epoch(model, dataloader, criterion, optimizer, scheduler, scaler, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    for images, targets in tqdm(dataloader, desc=\"Training\"):\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass with mixed precision\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backpropagation with gradient scaling\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # Update scheduler\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Track statistics\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Store predictions and targets for metrics\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_targets.extend(targets.cpu().numpy())\n",
        "        all_predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    f1_scores = f1_score(all_targets, all_predictions, average=None)\n",
        "    min_f1 = f1_scores.min()\n",
        "    avg_f1 = f1_score(all_targets, all_predictions, average='macro')\n",
        "\n",
        "    return epoch_loss, min_f1, avg_f1, f1_scores"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:43:41.082594Z",
          "iopub.execute_input": "2025-05-21T03:43:41.082869Z",
          "iopub.status.idle": "2025-05-21T03:43:41.090808Z",
          "shell.execute_reply.started": "2025-05-21T03:43:41.08285Z",
          "shell.execute_reply": "2025-05-21T03:43:41.089976Z"
        },
        "id": "j-P1jBDPa-Vp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# validation loop\n",
        "def valid_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in tqdm(dataloader, desc=\"Validation\"):\n",
        "            images, targets = images.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Track statistics\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # Store predictions and targets for metrics\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "            all_predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    f1_scores = f1_score(all_targets, all_predictions, average=None)\n",
        "    min_f1 = f1_scores.min()\n",
        "    avg_f1 = f1_score(all_targets, all_predictions, average='macro')\n",
        "\n",
        "    # Get per-class metrics\n",
        "    class_report = classification_report(all_targets, all_predictions, target_names=list(soil_types.keys()), output_dict=True)\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(all_targets, all_predictions)\n",
        "\n",
        "    return epoch_loss, min_f1, avg_f1, f1_scores, class_report, cm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:43:43.650433Z",
          "iopub.execute_input": "2025-05-21T03:43:43.650775Z",
          "iopub.status.idle": "2025-05-21T03:43:43.657584Z",
          "shell.execute_reply.started": "2025-05-21T03:43:43.650752Z",
          "shell.execute_reply": "2025-05-21T03:43:43.656702Z"
        },
        "id": "dDsu8Qqoa-Vp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter setup\n",
        "CONFIG = {\n",
        "    'IMG_SIZE': 384,\n",
        "    'BATCH_SIZE': 16,\n",
        "    'NUM_WORKERS': 4,\n",
        "    'EPOCHS': 20,\n",
        "    'LEARNING_RATE': 1e-4,\n",
        "    'WEIGHT_DECAY': 1e-4,\n",
        "    'MODEL_NAME': 'efficientnet_b3',\n",
        "    'NUM_CLASSES': 4,\n",
        "    'NUM_FOLDS': 5,\n",
        "    'DEVICE': device,\n",
        "    'EARLY_STOPPING': 5,  # Number of epochs to wait before early stopping\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:43:45.963894Z",
          "iopub.execute_input": "2025-05-21T03:43:45.964682Z",
          "iopub.status.idle": "2025-05-21T03:43:45.968892Z",
          "shell.execute_reply.started": "2025-05-21T03:43:45.964653Z",
          "shell.execute_reply": "2025-05-21T03:43:45.967999Z"
        },
        "id": "zG9V-qnAa-Vq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# defining k-fold cross validation for training\n",
        "def train_with_kfold(df, train_dir, config=CONFIG):\n",
        "    # Initialize KFold\n",
        "    kfold = StratifiedKFold(n_splits=config['NUM_FOLDS'], shuffle=True, random_state=42)\n",
        "\n",
        "    # Lists to store metrics across folds\n",
        "    fold_min_f1_scores = []\n",
        "    fold_models = []\n",
        "    best_min_f1 = 0\n",
        "    best_fold = 0\n",
        "\n",
        "    # Initialize class weights for loss function to handle class imbalance\n",
        "    class_counts = df['label'].value_counts().sort_index().values\n",
        "    weights = torch.FloatTensor(len(class_counts) / class_counts).to(config['DEVICE'])\n",
        "\n",
        "    # For each fold\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(df, df['label'])):\n",
        "        print(f\"\\n{'='*20} Fold {fold+1}/{config['NUM_FOLDS']} {'='*20}\")\n",
        "\n",
        "        # Split the data\n",
        "        train_data = df.iloc[train_idx].reset_index(drop=True)\n",
        "        val_data = df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "        print(f\"Training on {len(train_data)} samples, validating on {len(val_data)} samples\")\n",
        "\n",
        "        # Create datasets\n",
        "        train_dataset = SoilDataset(train_data, train_dir, transform=get_train_transforms(config['IMG_SIZE']))\n",
        "        val_dataset = SoilDataset(val_data, train_dir, transform=get_valid_transforms(config['IMG_SIZE']))\n",
        "\n",
        "        # Create dataloaders\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=config['BATCH_SIZE'],\n",
        "            shuffle=True,\n",
        "            num_workers=config['NUM_WORKERS'],\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=config['BATCH_SIZE'],\n",
        "            shuffle=False,\n",
        "            num_workers=config['NUM_WORKERS'],\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        # Initialize model\n",
        "        model = SoilClassifier(\n",
        "            model_name=config['MODEL_NAME'],\n",
        "            pretrained=True,\n",
        "            num_classes=config['NUM_CLASSES']\n",
        "        ).to(config['DEVICE'])\n",
        "\n",
        "        # Initialize optimizers and schedulers\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=config['LEARNING_RATE'], weight_decay=config['WEIGHT_DECAY'])\n",
        "\n",
        "        # Use weighted cross-entropy loss for class imbalance\n",
        "        criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer,\n",
        "            T_max=config['EPOCHS'] * len(train_loader),\n",
        "            eta_min=1e-6\n",
        "        )\n",
        "\n",
        "        # Initialize gradient scaler for mixed precision training\n",
        "        scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        # Training loop\n",
        "        best_val_min_f1 = 0\n",
        "        no_improvement_count = 0\n",
        "        fold_best_model = None\n",
        "\n",
        "        for epoch in range(config['EPOCHS']):\n",
        "            print(f\"\\nEpoch {epoch+1}/{config['EPOCHS']}\")\n",
        "\n",
        "            # Train\n",
        "            train_loss, train_min_f1, train_avg_f1, train_class_f1 = train_epoch(\n",
        "                model, train_loader, criterion, optimizer, scheduler, scaler, config['DEVICE']\n",
        "            )\n",
        "\n",
        "            # Validate\n",
        "            val_loss, val_min_f1, val_avg_f1, val_class_f1, val_report, val_cm = valid_epoch(\n",
        "                model, val_loader, criterion, config['DEVICE']\n",
        "            )\n",
        "\n",
        "            # Print metrics\n",
        "            print(f\"Train Loss: {train_loss:.4f}, Train Min F1: {train_min_f1:.4f}, Train Avg F1: {train_avg_f1:.4f}\")\n",
        "            print(f\"Val Loss: {val_loss:.4f}, Val Min F1: {val_min_f1:.4f}, Val Avg F1: {val_avg_f1:.4f}\")\n",
        "            print(\"Class-wise F1 scores:\")\n",
        "            for i, soil_type in enumerate(soil_types.keys()):\n",
        "                print(f\"{soil_type}: {val_class_f1[i]:.4f}\")\n",
        "\n",
        "            # Check if this is the best model for this fold\n",
        "            if val_min_f1 > best_val_min_f1:\n",
        "                best_val_min_f1 = val_min_f1\n",
        "                fold_best_model = model.state_dict().copy()\n",
        "                no_improvement_count = 0\n",
        "                print(f\"New best model with min F1 score: {best_val_min_f1:.4f}\")\n",
        "            else:\n",
        "                no_improvement_count += 1\n",
        "                print(f\"No improvement for {no_improvement_count} epochs\")\n",
        "\n",
        "            # Early stopping\n",
        "            if no_improvement_count >= config['EARLY_STOPPING']:\n",
        "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                break\n",
        "\n",
        "        # Store the best min F1 score for this fold\n",
        "        fold_min_f1_scores.append(best_val_min_f1)\n",
        "\n",
        "        # Create a new model instance and load the best weights\n",
        "        best_model = SoilClassifier(\n",
        "            model_name=config['MODEL_NAME'],\n",
        "            pretrained=False,\n",
        "            num_classes=config['NUM_CLASSES']\n",
        "        ).to(config['DEVICE'])\n",
        "        best_model.load_state_dict(fold_best_model)\n",
        "        fold_models.append(best_model)\n",
        "\n",
        "        # Check if this is the best fold overall\n",
        "        if best_val_min_f1 > best_min_f1:\n",
        "            best_min_f1 = best_val_min_f1\n",
        "            best_fold = fold\n",
        "\n",
        "        # Clear memory\n",
        "        del model, train_dataset, val_dataset, train_loader, val_loader\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # Print fold results\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"K-fold Cross-validation Results:\")\n",
        "    for fold, score in enumerate(fold_min_f1_scores):\n",
        "        print(f\"Fold {fold+1}: Min F1 = {score:.4f}\")\n",
        "    print(f\"Average Min F1: {np.mean(fold_min_f1_scores):.4f}\")\n",
        "    print(f\"Best fold: {best_fold+1} with Min F1 = {best_min_f1:.4f}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    return fold_models, best_fold"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:43:46.324083Z",
          "iopub.execute_input": "2025-05-21T03:43:46.324854Z",
          "iopub.status.idle": "2025-05-21T03:43:46.339189Z",
          "shell.execute_reply.started": "2025-05-21T03:43:46.324825Z",
          "shell.execute_reply": "2025-05-21T03:43:46.338488Z"
        },
        "id": "9UcNxMcSa-Vq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# executing the training loop\n",
        "models, best_fold = train_with_kfold(train_df, TRAIN_DIR)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T03:43:50.902689Z",
          "iopub.execute_input": "2025-05-21T03:43:50.902989Z",
          "iopub.status.idle": "2025-05-21T04:13:14.065445Z",
          "shell.execute_reply.started": "2025-05-21T03:43:50.902966Z",
          "shell.execute_reply": "2025-05-21T04:13:14.064507Z"
        },
        "id": "RDT6JqjOa-Vr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# saves the best k-fold model\n",
        "best_model = models[best_fold]\n",
        "torch.save(best_model.state_dict(), 'best_soil_model.pth')\n",
        "print(f\"Best model (fold {best_fold+1}) saved to 'best_soil_model.pth'\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T04:13:30.007027Z",
          "iopub.execute_input": "2025-05-21T04:13:30.007328Z",
          "iopub.status.idle": "2025-05-21T04:13:30.128759Z",
          "shell.execute_reply.started": "2025-05-21T04:13:30.007303Z",
          "shell.execute_reply": "2025-05-21T04:13:30.128044Z"
        },
        "id": "SGZWBSOia-Vr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# inference code and submission.csv creation\n",
        "def predict(models, test_df, test_dir, config=CONFIG):\n",
        "    # Create test dataset\n",
        "    test_dataset = SoilDataset(\n",
        "        test_df,\n",
        "        test_dir,\n",
        "        transform=get_valid_transforms(config['IMG_SIZE']),\n",
        "        test=True\n",
        "    )\n",
        "\n",
        "    # Create test dataloader\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config['BATCH_SIZE'],\n",
        "        shuffle=False,\n",
        "        num_workers=config['NUM_WORKERS'],\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    # Dictionary to map indices back to soil types\n",
        "    idx_to_soil = {v: k for k, v in soil_types.items()}\n",
        "\n",
        "    # Make predictions\n",
        "    all_predictions = []\n",
        "\n",
        "    for model in models:\n",
        "        model.eval()\n",
        "        model_preds = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images in tqdm(test_loader, desc=\"Predicting\"):\n",
        "                images = images.to(config['DEVICE'])\n",
        "                outputs = model(images)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                model_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        all_predictions.append(model_preds)\n",
        "\n",
        "    # Convert predictions to numpy array for easier manipulation\n",
        "    all_predictions = np.array(all_predictions)\n",
        "\n",
        "    # Take the mode of predictions from all models (ensemble)\n",
        "    final_predictions = []\n",
        "    for i in range(len(test_df)):\n",
        "        # Get predictions from all models for this sample\n",
        "        sample_preds = all_predictions[:, i]\n",
        "\n",
        "        # Find the most common prediction (mode)\n",
        "        values, counts = np.unique(sample_preds, return_counts=True)\n",
        "        mode_idx = values[np.argmax(counts)]\n",
        "\n",
        "        # Convert index to soil type\n",
        "        final_predictions.append(idx_to_soil[mode_idx])\n",
        "\n",
        "    # Create submission dataframe\n",
        "    submission_df = test_df.copy()\n",
        "    submission_df['soil_type'] = final_predictions\n",
        "\n",
        "    return submission_df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T04:13:31.747303Z",
          "iopub.execute_input": "2025-05-21T04:13:31.748345Z",
          "iopub.status.idle": "2025-05-21T04:13:31.756786Z",
          "shell.execute_reply.started": "2025-05-21T04:13:31.748312Z",
          "shell.execute_reply": "2025-05-21T04:13:31.755926Z"
        },
        "id": "9BbRWnd3a-Vr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# executing inference and submission.csv creation code\n",
        "submission_df = predict(models, test_df, TEST_DIR)\n",
        "\n",
        "# Save submission\n",
        "submission_df[['image_id', 'soil_type']].to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T04:13:36.17956Z",
          "iopub.execute_input": "2025-05-21T04:13:36.180335Z",
          "iopub.status.idle": "2025-05-21T04:13:49.08809Z",
          "shell.execute_reply.started": "2025-05-21T04:13:36.180295Z",
          "shell.execute_reply": "2025-05-21T04:13:49.086826Z"
        },
        "id": "YVBqIAPBa-Vs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing our predictions\n",
        "def visualize_predictions(model, test_df, test_dir, num_samples=10, config=CONFIG):\n",
        "    # Get a random sample of test images\n",
        "    sample_indices = np.random.choice(len(test_df), num_samples, replace=False)\n",
        "    sample_df = test_df.iloc[sample_indices].reset_index(drop=True)\n",
        "\n",
        "    # Create simple transforms for visualization\n",
        "    transform = A.Compose([\n",
        "        A.Resize(config['IMG_SIZE'], config['IMG_SIZE']),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "    # Dictionary to map indices back to soil types\n",
        "    idx_to_soil = {v: k for k, v in soil_types.items()}\n",
        "\n",
        "    # Set up the figure\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for i, idx in enumerate(sample_indices):\n",
        "        # Load and preprocess the image\n",
        "        img_path = os.path.join(test_dir, test_df.iloc[idx]['image_id'])\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # For display\n",
        "        display_img = cv2.resize(img, (config['IMG_SIZE'], config['IMG_SIZE']))\n",
        "\n",
        "        # For prediction\n",
        "        transformed = transform(image=img)\n",
        "        tensor_img = transformed['image'].unsqueeze(0).to(config['DEVICE'])\n",
        "\n",
        "        # Make prediction\n",
        "        with torch.no_grad():\n",
        "            output = model(tensor_img)\n",
        "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "            max_prob, prediction = torch.max(probabilities, 1)\n",
        "\n",
        "        # Get predicted soil type\n",
        "        pred_soil = idx_to_soil[prediction.item()]\n",
        "        confidence = max_prob.item() * 100\n",
        "\n",
        "        # Display image and prediction\n",
        "        axes[i].imshow(display_img)\n",
        "        axes[i].set_title(f\"Pred: {pred_soil}\\nConf: {confidence:.1f}%\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T04:14:22.269407Z",
          "iopub.execute_input": "2025-05-21T04:14:22.270251Z",
          "iopub.status.idle": "2025-05-21T04:14:22.279407Z",
          "shell.execute_reply.started": "2025-05-21T04:14:22.270223Z",
          "shell.execute_reply": "2025-05-21T04:14:22.278693Z"
        },
        "id": "EweKQ-zKa-Vs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# executing the visualize function\n",
        "visualize_predictions(best_model, test_df, TEST_DIR)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T04:14:40.676266Z",
          "iopub.execute_input": "2025-05-21T04:14:40.677072Z",
          "iopub.status.idle": "2025-05-21T04:14:42.608526Z",
          "shell.execute_reply.started": "2025-05-21T04:14:40.677045Z",
          "shell.execute_reply": "2025-05-21T04:14:42.607332Z"
        },
        "id": "DyPzrcPEa-Vt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "o323kVPIa-Vt"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}